{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Begin to implement chains and implement a pipeline "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a14907c50f72281e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"job_desc.md\") as f:\n",
    "    description = f.read()\n",
    "with open(\"resume.md\") as f:\n",
    "    resume = f.read()\n",
    "title = 'django developer'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T01:49:55.168120Z",
     "start_time": "2023-08-10T01:49:55.155648Z"
    }
   },
   "id": "4fc08de57fa9144c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-10T01:49:56.624484Z",
     "start_time": "2023-08-10T01:49:56.611205Z"
    }
   },
   "outputs": [],
   "source": [
    "from util import chunk_markdown, cut_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sections = cut_sections(resume)\n",
    "\n",
    "history = sections['history']['result']\n",
    "chunks = chunk_markdown(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T01:50:24.482851Z",
     "start_time": "2023-08-10T01:49:57.071365Z"
    }
   },
   "id": "57981bbfa705076"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need a function to only select job history from chunks. Any other headings such as summary, or education should be set aside."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43ede2c2963f10a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin to process job history chunks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5ac5bb20db66a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Implementing `process_history_chain()`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73bdd1a7a81a5138"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'skills'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m chain \u001B[38;5;241m=\u001B[39m process_history_chain()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunks:\n\u001B[0;32m----> 5\u001B[0m     \u001B[43mchain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msection\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtitle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdesc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repos/resume_slayer/venv/lib/python3.11/site-packages/langchain/chains/base.py:235\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    202\u001B[0m     inputs: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Any],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    208\u001B[0m     include_run_info: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    209\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[1;32m    210\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \n\u001B[1;32m    212\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;124;03m            `Chain.output_keys`.\u001B[39;00m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 235\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprep_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m     callback_manager \u001B[38;5;241m=\u001B[39m CallbackManager\u001B[38;5;241m.\u001B[39mconfigure(\n\u001B[1;32m    237\u001B[0m         callbacks,\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata,\n\u001B[1;32m    244\u001B[0m     )\n\u001B[1;32m    245\u001B[0m     new_arg_supported \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/repos/resume_slayer/venv/lib/python3.11/site-packages/langchain/chains/base.py:389\u001B[0m, in \u001B[0;36mChain.prep_inputs\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m     external_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory\u001B[38;5;241m.\u001B[39mload_memory_variables(inputs)\n\u001B[1;32m    388\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mexternal_context)\n\u001B[0;32m--> 389\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "File \u001B[0;32m~/repos/resume_slayer/venv/lib/python3.11/site-packages/langchain/chains/base.py:147\u001B[0m, in \u001B[0;36mChain._validate_inputs\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    145\u001B[0m missing_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_keys)\u001B[38;5;241m.\u001B[39mdifference(inputs)\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing_keys:\n\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing some input keys: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_keys\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Missing some input keys: {'skills'}"
     ]
    }
   ],
   "source": [
    "from beef import process_history_chain\n",
    "\n",
    "chain = process_history_chain()\n",
    "for chunk in chunks:\n",
    "    chain({\"section\": chunk, \"title\": title, \"desc\": description})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T01:50:25.795871Z",
     "start_time": "2023-08-10T01:50:25.735464Z"
    }
   },
   "id": "dd812a73bad7b0f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "How do we highlight key skills?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cd190b0e623c4f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from util import job_requirement_chain\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "requirement_chain = job_requirement_chain()\n",
    "prompt = PromptTemplate(template=\"\"\"\n",
    "You're an expert career consultant with an IQ over 140 working with a special client regarding this job posting.\n",
    "You will be given a list of required skills, and an excerpt from the client's resume.\n",
    "What required 3 skills does the client have?\n",
    "\n",
    "Resume excerpt:\\n\\t{section}\n",
    "\n",
    "Required skills:\\n\\t{requirements}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "                        input_variables=['section', 'requirements'],\n",
    "                        partial_variables={'format_instructions': format_instructions}\n",
    "                                      )\n",
    "key_skill_chain = LLMChain(prompt=prompt, llm=ChatOpenAI(temperature=.1, model_name=\"gpt-3.5-turbo\"), output_parser=output_parser)\n",
    "key_skill_chain.predict(section=chunks[0], requirements=requirement_chain.predict(description=description))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e426ea86f9bb4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skills = _17\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You will be given a job experience from a resume and 3 key skills.\n",
    "Use bullet points to highlight how the job experience section demonstrates the given skills.\n",
    "\n",
    "Skills: {skills}\n",
    "\n",
    "Job Experience: {section} \n",
    "\"\"\")\n",
    "# prompt = PromptTemplate.from_template(\"\"\"\n",
    "# You will be given a section of a resume and 3 key skills.\n",
    "# Please write a one sentence summary for the resume section highlighting some or all of the given skills.\n",
    "# \n",
    "# Skills: {skills}\n",
    "# \n",
    "# Section: {section} \n",
    "# \"\"\")\n",
    "highlight_chain = LLMChain(prompt=prompt, llm=ChatOpenAI(temperature=.1, model_name=\"gpt-3.5-turbo\"))\n",
    "highlight_chain.predict(section=chunks[0], skills=skills)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cff50b60f263f9a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that a router should be used to evaluate a job experience section. If a job experience section is not strong for a given job description, THAN the chains described in this notebook should be used. This chain should be called `BeefSectionChain`. It's intention should be to highlight the key skills needed for a given job description."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e04cb90cc522d6db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "380765b58785016a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
